# General Guidance

学习模型 + 学习准则 + 学习算法 = 最优化模型

机器学习根据输入输出的不同（训练样本提供的信息以及反馈方式）可分为下面几种情景（Scenario）：

- 监督学习 Supervised Learning
- 半监督学习 Semi-supervised Learning
- 无监督学习 Unsupervised Learning
- 迁移学习 Transfer Learning
- 强化学习 Reinforcement Learning

![ML](<img/ML.jpg>)

每一种情景中，根据输出的不同可分为下面几种任务（task）：

- 回归 Regression
- 分类 Classification
- Structure Learning 特殊的分类问题，输出的空间很大

每一种任务中，根据模型的特征可以分类：

- 线性模型 | 非线性模型

- 参数化模型（参数维度固定） | 非参数化模型（参数课自由增减）

- 非概率模型（判别模型） | 概率模型（生成模型）

  > 判别式模型（Discriminative Model）是直接对条件概率p(y|x;θ)建模。常见的判别式模型有：线性回归模型、线性判别分析、支持向量机SVM、神经网络、boosting、条件随机场等。
  >
  > 举例：要确定一个羊是山羊还是绵羊，用判别模型的方法是从历史数据中学习到模型，然后通过提取这只羊的特征来预测出这只羊是山羊的概率，是绵羊的概率。
  >
  > 生成式模型（Generative Model）则会对x和y的联合分布p(x,y)建模，然后通过贝叶斯公式来求得p(yi|x)，然后选取使得p(yi|x)最大的yi。常见的生成式模型有：隐马尔可夫模型HMM、朴素贝叶斯模型、高斯混合模型GMM、LDA、高斯、混合多项式、专家的混合物、马尔可夫的随机场。
  >
  > 举例：利用生成模型是根据山羊的特征首先学习出一个山羊的模型，然后根据绵羊的特征学习出一个绵羊的模型，然后从这只羊中提取特征，放到山羊模型中看概率是多少，在放到绵羊模型中看概率是多少，哪个大就是哪个。
  >
  > <https://www.cnblogs.com/nolonely/p/6435213.html>

## Model 学习模型 \ Learner 学习器

- 传统机器学习
- 深度学习
- 结构学习

## Evaluation Criterion 学习准则

### Loss Function 损失函数

Loss函数的海塞矩阵（二次微分）

- 正定，特征值全为正，局部最低点
- 负定，特征值全为负，局部最高点
- 特征值一些正，一些负，鞍点

可以用海塞矩阵的特征向量来逃离鞍点，用一些梯度下降方向的修正就可以避免卡鞍点的问题。

在大型的网络中，大部分的局部最低点都是等价的。

不同的初始权重设置、或者不同的下降方法，最后到达的局部最小值，很可能是不同的地方。

### 经验风险、结构风险、期望风险

- 经验风险：模型在训练集上的平均损失（在训练集上的误差）

  > 当样本容量足够大时，经验风险最小化能保证有很好的学习效果，此时按照经验风险最小化求最优模型即可。
  >
  > 当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计（频率学派）。

- 结构风险：在训练集上，为了不至于过拟合，而加上了正则化项之后，模型在训练集上的平均损失

  > 当样本容量很小时，经验风险最小化学习易产生过拟合的问题，此时按照结构风险最小化求最优模型即可。
  >
  > 当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化就等价于最大后验概率估计（贝叶斯学派）。
  >
  > <https://zhuanlan.zhihu.com/p/40024110>

- 期望风险：模型在总体数据集上的平均损失（在未知样本上的泛化误差，可以靠样本容量的增大使经验风险或结构风险逼近期望风险，但不会等同）

## Algorithm 学习算法

求解最优化问题的算法

常用（小批量）梯度下降

## Evaluation Metrics 评价指标

之所以不能用下面这些评价指标作为学习准则，是因为这些东西对于隐参数来说不可导，所以它们只能作为模型的性能度量。

### Accuracy 准确率

### Error Rate 错误率

### 查准率、查全率、F1

### ROC、AUC

# 监督学习

把大象放到冰箱里：

1. 定义模型（输入、参数、输出）、损失函数、训练方法（优化方法）
2. 在训练集上训练，在验证集上预测（或者利用[交叉验证](#Cross Validation 交叉验证法)的方法在预测集之外的所有样本上训练+预测），看看评价指标，若不满意，返回步骤1调整模型
3. 在预测集上预测，看看评价指标，若不满意，返回步骤1调整模型
4. 完工。在预测集上的评价指标作为模型的性能。

## Train+Validation+Test

为什么要三份？

如果只有Training set和Testing set，就可能有一个只会随机产生权重的学习器，经过多次尝试（在Training set上“训练”），总可以找到一个能使Testing set上loss为0的学习器，但这在实际应用时就成废物了。这里，Testing set就相当于被用来调参了，而学习器在调参过程中的loss表现只是在**已知**样本中的表现，在未知样本中的表现不一定会好。

如果加一个Validation set用于调参，最后再在Testing set上模拟在未知样本上的表现，就可以反映出实际应用时的表现了。

注：调参的过程实际上也是学习，只不过是人为地对学习器结构的矫正。这个过程是让学习器事先接触一些未知的样本，一步步地，学习器将在Training set和Validation set上都达到很好的效果，也就是将未知吞并为已知、在Training set和Validation set都走向过拟合。

猜测：应该也可以实现准备多个Validation set，进行多阶段的接触未知。所以这就相当于是，喂进去更多的学习样本，同时一步步地人为矫正学习器的结构。

## Cross Validation 交叉验证法

用于评价 模型 与 优化算法 本身的优劣，所以是拿一个初始化的模型，现场训练、现场评估

- k折交叉验证（k-fold cross validation）：100个样本，$k=10$折即将100个样本随机分裂成10份，每一折由9份作为训练集+1份作为测试集构成，总共10种分配方式，总共训练+预测10次，将10次的评价指标进行平均，作为最终的评价指标

- n次k折交叉验证：因为k折交叉验证中的样本分裂是随机的，所以应该重复实验，重复n次（总共进行$n*k$次训练+预测），再对n个k折出的平均值进行平均，作为最终的评价指标

- 留一法（Leave-One-Out，简称LOO）：k = m = len(样本集)，虽然这种评估比较准确，但耗时太严重（有几个样本就要训练几次）

- 自助法（bootstrapping）：随机抽取一个样本放入训练集，之后放回样本集，这样随机抽取出 m=len(样本集) 个构成训练集，再求样本集与训练集的集合减法，获得测试集。由于样本在m次采样中始终不被采到的概率为$(1-\frac{1}{m})^m$，当$m \to \infty$时就有$\displaystyle{\lim_{m \to \infty}} (1-\frac{1}{m})^m \approx \frac{1}{e}\approx36.8\%$的样本构成了测试集，同时又有m个训练样本。

  > 自助法在数据集较小、难以有效划分训练/测试集时很有用；此外，自助法能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处。然而，自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。因此,在初始数据量足够时，留出法和交叉验证法更常用一些。

## Optimizing 优化

![loss_optimizing](<img/loss_optimizing.jpg>)

如果发现test set上的loss太大了，想要优化，可以分成两种解决方案：

- train set上的loss大，欠拟合
  - 模型表征能力太弱——加强表征能力
  - 优化能力不足，陷入了局部最小值——更好的优化学习方法（如何判断是模型表征能力太弱，还是优化能力不足？可以先看看较弱的学习器的loss：如果较弱的学习器的loss更低，说明是优化能力不足；如果较弱的学习器的loss更高，说明模型表征能力太弱。）
  - 其他
- train set上的loss小，过拟合
  - 过拟合——喂更多的数据、Data Augmentation、减弱表征能力、减少输入的特征维度、Early Stopping、Regularization、Dropout
  - Mismatch: testing set不符合training set的规律（牛头不对马嘴）（一般不考虑这种情况）

注：带星号*的专属于神经网络

### 应对欠拟合

#### 加强表征能力

换更强学习器

神经网络加深层

#### 更好的优化学习方法

如何更好地让loss下降？

##### Batch Train

大批量的运算时间短

小批量的可能有利于优化

![batch_train](<img/batch_train.jpg>)

##### 更好的Activation Function*

因为Sigmoid激活函数的特性，深层神经网络存在梯度消失和梯度爆炸的问题

可以换成Relu、Relu变种、MaxOut来缓解

##### 更好的Loss Function

Cross Entrophy比Mean Square好

##### 更好的Optimizer

朴素的SGD太low了

![optimizer](<img/optimizer.jpg>)

###### 学习率计划调控、宏观调控（Learning Rate Scheduling）

- 慢慢衰减：Decay

  ![learning_rate_scheduling3](<img/learning_rate_scheduling3.jpg>)

- 先慢慢增大再慢慢减小（适用于学习率自适应调整，防止初始的时候梯度加和太偏激）：Warm Up

  ![learning_rate_scheduling](<img/learning_rate_scheduling.jpg>)

- 周期性变化：Cyclic Learning Rate、Warm Restarts

  ![learning_rate_scheduling2](<img/learning_rate_scheduling2.jpg>)

###### 学习率自适应调整

AdaGrad：σ = 过去的梯度幅值的加和平均（平方加和求平均再开根号），之前的梯度幅值的加和平均越大，学习率越小。

红色框里的就是修正后的学习率。

![adagrad](<img/adagrad.jpg>)

RMSprop：在AdaGrad的基础上，用α调控 过去的梯度幅值的加和平均 与 当前梯度幅值 的比率

α是超参数。α越接近0，就越注重新鲜出炉的梯度，学习率的调整的响应速度也就越迅速。α越接近0，反之。

![rmsprop](<img/rmsprop.jpg>)

###### 梯度方向的修正

- Momentum
- Nesterov

![momentum](<img/momentum.jpg>)

###### 综合optimizer

Adam = Momentum + RMSprop

#### 其他

##### 参数初始化*

##### 数据预处理

##### Batch Normalization*

![feature_scaling1](<img/feature_scaling1.jpg>)

![feature_scaling2](<img/feature_scaling2.jpg>)

因为输入的多维数据中，对问题的解的重要性、贡献度有多有少，这导致在loss的下降中不同的维度（方向）的步幅（learning rate）应该存在或多或少的不同，但不方便改变步幅，那就通过normalization将输入值进行Feature Scaling好了，即对输入的各维数据都进行归一化。

在每一层神经网络之间，都可以对输出的z做normalization。

batch指的是batch train。

在跑test时就没有batch来计算平均数和方差了，所以在train的时候要记录下所有batch train的平均数和方差，最后平均一下，作为batch normalization层的固定参数。

batch normalization能使学习加速，能减少梯度爆炸、消失，能减小初始权重的设置对学习的影响，也允许设置更大的learning rate了。

![batch_normalization](<img/batch_normalization.jpg>)

### 应对过拟合

#### More Training Data

喂更多的数据

#### Data Augmentation

数据增强

#### Less parameters

减弱表征能力，共用参数

#### Less features

减少输入的特征维度

#### Early Stopping

不要一直等到train set上的loss下降到最低，validation set的loss最小的时候就停止训练！

![earlystopping](<img/earlystopping.png>)

#### Regularization

正则化惩罚

Loss Function中加上模型所有weight（不用考虑bias！）的p范数项 乘上 一个超参数λ（调节平滑度），以便让模型的参数趋于0，让模型变得平滑——对training data中的噪声不那么敏感——不那么过拟合

导致variance变小，bias变大

#### Dropout*



# Deep Learning

当你用把一个偏置和一堆非线性函数相加构成了一个复杂函数时，就构造出了一层神经网络。

![FromLinearToNN](<img/FromLinearToNN.jpg>)

而这个非线性的函数就是激活函数

![FromLinearToNN2](<img/FromLinearToNN2.jpg>)

如果再叠加几层，就变成了“深”层神经网络，也就是“深度”的学习

![FromLinearToNN3](<img/FromLinearToNN3.jpg>)

## 为什么是深层网络而不是肥胖网络？

即使只有一层隐层，只要有足够的神经元，神经网络理论上可以拟合任意连续函数。为什么还要使用深层网络结构？

- 浅层网络 为了获得与 深层网络 相同的表征能力，所需的参数更多，深层网络的性能更好而且更容易训练
- 深层网络中每一层的功能相当于一次抽象，具有模块化学习的思想

## 激活函数(Activation Function)

为了增强网络的表征能力和学习能力，激活函数应该：

- 连续，可导（少数点可以不可导）：为了反向传播
- 非线性：否则再多的层，也是个线性模型
- 激活函数和它的导数尽可能简单（对应的问题：计算开销）
- 零中心化（对应的问题：偏执转移）
- 导数的值域在一定的范围内，不能过大也不能过小（对应的问题：梯度爆炸，梯度消失）

### Sigmoid

S型曲线，两端饱和

![sigmoid](<img/sigmoid.jpg>)

#### Logistic

$$
\sigma(x)=\frac{x}{1+e^x}
$$

#### Tanh

$$
tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}=2\sigma(2x)-1
$$

### ReLU(Rectified Linear Unit)

![ReLUs](<img/ReLUs.jpg>)

#### Basic ReLU

#### Leaky ReLU

#### ELU(Exponential Linear Unit)

#### PReLU(Parametric ReLU)

带参数的ReLU

#### Softplus

$$
Softplus(x)=\ln(1+e^x)
$$

### Swish

### GELU

### Maxout

### 问题

#### 计算开销

嫌$\exp(x)$计算消耗太大？

- Hard-Logistic
- Hard-Tanh

#### 偏执转移(Bias Shift)

非零中心化的激活函数，导致下一层的输入全部为正，由于
$$
f=\sum(w^T+x_i)+b
$$
$$
\frac{df}{dw_i}=x_i
$$

$$
\frac{dL}{dw_i}=\frac{dL}{df}\frac{df}{dw_i}=\frac{dL}{df}*x_i
$$

使得在同一层内，因为$x_i$全为正，且$\frac{dL}{df}$的正负由误差决定，所以$\frac{dL}{dw_i}$就全部同号了，这使得反向传播更新$w$的方向受限，学习效率低下。

Logistic和ReLu都有这个问题，所以就有了在每个ReLU之后加一层[Batch Norm](#Batch Normalization*)的操作

> *Sigmoid outputs are not zero-centered*. This is undesirable since neurons in later layers of processing in a Neural Network (more on this soon) would be receiving data that is not zero-centered. This has implications on the dynamics during gradient descent, because if the data coming into a neuron is always positive (e.g. $x>0$ elementwise in $f=\sum(w^T+x_i)+b$ ), then the gradient on the weights ww will during backpropagation become either all be positive, or all negative (depending on the gradient of the whole expression $f$). This could introduce undesirable zig-zagging dynamics in the gradient updates for the weights. However, notice that once these gradients are added up across a batch of data the final update for the weights can have variable signs, somewhat mitigating this issue. Therefore, this is an inconvenience but it has less severe consequences compared to the saturated activation problem above.
>
> ---
>
> [Why are non zero-centered activation functions a problem in backpropagation?](<https://stats.stackexchange.com/questions/237169/why-are-non-zero-centered-activation-functions-a-problem-in-backpropagation>)

#### 梯度爆炸、梯度消失

层数很多，且如果梯度逐层累积（指数级），就造成了梯度爆炸和梯度消失。（这里需要更严谨的解释）

解决方法：梯度剪切、权重正则化、残差、LSTM

另外梯度消失还可能是激活函数的原因，两端饱和，导致梯度过小

> *Sigmoids saturate and kill gradients*. A very undesirable property of the sigmoid neuron is that when the neuron’s activation saturates at either tail of 0 or 1, the gradient at these regions is almost zero. Recall that during backpropagation, this (local) gradient will be multiplied to the gradient of this gate’s output for the whole objective. Therefore, if the local gradient is very small, it will effectively “kill” the gradient and almost no signal will flow through the neuron to its weights and recursively to its data. Additionally, one must pay extra caution when initializing the weights of sigmoid neurons to prevent saturation. For example, if the initial weights are too large then most neurons would become saturated and the network will barely learn.

解决方法：Batch Norm、RuLU变种

## 反向传播

### 手动梯度

一个个手算，然后编程

### 数值微分

对于每个参数，计算微小增量对Loss的改变，暴力微分

### 符号微分

定义方程，编译后自动计算出算导函数，反向传播的时候代入数值

### 自动微分

计算图

![computation_graph](<img/computation_graph.jpg>)

如图所示，反向传播的计算顺序是，将信号$E$乘以节点的局部导数$\frac{\partial y}{\partial x}$，然后将结果传递给下一个节点。这里所说的局部导数是指正向传播中$y=f(x)$的导数，也就是$y$关于$x$的导数$\frac{\partial y}{\partial x}$。比如，假设$y=f(x)=x^2$，则局部导数为$\frac{\partial y}{\partial x} = 2x$。把这个局部导数乘以上游传过来的值（本例中为$E$），然后传递给前面的节点。

## 前馈神经网络

### 全连接网络(Fully-connected neural network, FCNN)

### 卷积神经网络(Convolutional Neural Network, CNN)

输入宽度$M$，卷积核宽度$K$，步长$S$，填充$P$，则输出宽度为$(M-K+2P)/S+1$

如果还涉及膨胀卷积（dilation），膨胀率D，则输出宽度为$(M-D*(K-1)+2P-1)/S+1$

> PyTorch参数讲解与示例（图片来源 <https://towardsdatascience.com/conv2d-to-finally-understand-what-happens-in-the-forward-pass-1bbaafb0b148>）
>
> `torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)`
>
> ---
>
> 如下图`Conv2d(in_channels=2, out_channels=2, kernel_size=(3,3), stride=(1,1), padding=(1,1), dilation=(1,1), groups=1)`
>
> 高度计算：$(7-1*(3-1)+2*1-1)/1+1=7$
>
> 宽度计算：同上
>
> ![Conv2D0](<img/Conv2D0.gif>)
>
> ---
>
> 如下图`Conv2d(in_channels=3, out_channels=2, kernel_size=(3,3), stride=(1,3), padding=(0,0), dilation=(1,1), groups=1)`
>
> 高度计算：$(9-1*(3-1)+2*0-1)/1+1=7$
>
> 宽度计算：$(9-1*(3-1)+2*0-1)/3+1=3$
>
> ![Conv2D1](<img/Conv2D1.gif>)
>
> ---
>
> 如下图`Conv2d(in_channels=3, out_channels=2, kernel_size=(5,2), stride=(1,1), padding=(0,0), dilation=(1,1), groups=1)`
>
> 高度计算：$(7-1*(5-1)+2*0-1)/1+1=3$
>
> 宽度计算：$(9-1*(2-1)+2*0-1)/1+1=8$
>
> ![Conv2D2](<img/Conv2D2.gif>)
>
> ---
>
> 如下图`Conv2d(in_channels=2, out_channels=1, kernel_size=(3,3), stride=(1,1), padding=(2,2), dilation=(4,2), groups=1)`
>
> dilation扩张的程度，$dilation-1$就是扩张出的间隔
>
> 高度计算：$(9-4*(3-1)+2*2-1)/1+1=5$
>
> 宽度计算：$(9-2*(3-1)+2*2-1)/1+1=9$
>
> ![Conv2D3](<img/Conv2D3.gif>)
>
> ---
>
> 如下图`Conv2d(in_channels=2, out_channels=4, kernel_size=(3,3), stride=(2,2), padding=(2,2), dilation=(1,1), groups=2)`
>
> group是给卷积层分组
>
> $group=n$，相当于把原先的卷积层，分裂成$n$个输入为$\frac{in\_channels}{n}$输出为$\frac{out\_channels}{n}$的子卷积层。
>
> 当$group=in\_channels$时，就是对每个输入通道进行独立卷积，相当于对特征的区分对待。
>
> 高度计算：$(7-1*(3-1)+2*2-1)/2+1=5$
>
> 宽度计算：同上
>
> ![Conv2D4](<img/Conv2D4.gif>)
>
> ---
>
> Channel和Group的对比
>
> - Channel是一个卷积层内“多堆”卷积核造成的多通道输出（输入的通道，通过一堆卷积核，卷出来一个输出通道）（所有的输入通道混在一起成为一个输出通道）
> - Group是一个卷积层分裂输入通道，分组分别卷积（输入通道分别形成多组输出通道）（这才是AlexNet中分裂出两支的方法）


#### 卷积层(Convolutional Layer)

对于宽$M$、高$N$、通道数$D$的输入层$M*N*D$，拿宽$U$、高$V$、的$P$个核$U*V*P*D$去提取特征，出来$P$个特征组，每组里面有$D$个通道，每个通道的宽为$M^*$，高为$N^*$。

#### 汇聚层（Pooling Layer）

下采样（会造成信息损失

没有需要学习的参数，是一个固定的Function

最初的目的是为了减少计算成本，现在Pooling的含量越来越小，趋向于全卷积网络。

如果对精细结构有要求，就不要用Pooling了！（Alpha Go就没有用😜）

## CNN



## 生成对抗网络(Generative Adversarial Network, GAN)

G：Generator

D：Discriminator

用G训练（固定G训练D），再用D训练G（固定D训练G），循环往复，互相促进，最后用来生成图片的是G。

![GAN0](<img/GAN0.png>)

### Basic GAN

输入分布Z中的随机采样z，生成类似分布X中x的G(z)（可以观察到，随着z的连续变化，G(z)也会连续地转变）

G：输入随机的分布z，输出与原始信号x同尺寸的G(z)

D：输入 [ 真实的信号x, 生成的信号G(z)] 的拼接数据，输出判断是否像真的(真伪二分类 或 0-1的回归)

训练：随机生成z，随机选x，D-G-D-G重复训练

实际的应用：生成随机分布的信号

- 生成图片
- 生成音频
- ……

![GAN1](<img/GAN1.png>)

### Conditional GAN (with Paired Data)

需要有**明确指向**的信号生成，而不是Basic GAN中在分布Z中随机采样出z来生成G(z)

于是在训练的时候，不仅需要原始的信号和生成的信号，还需要各自的标签

G：输入随机的分布z和需要生成的类型label（可以是离散的属性值，也可以是各种具有物理属性的向量），输出与原始信号x同尺寸的G(z)

D：输入 [ (真实的信号x, 真实的label), (生成的信号G(z), 生成信号对应label) ]，输出判断是否像真的(真伪二分类 或 0-1的回归)

训练：

- 选择相匹配的label，训练D（正向刺激
- 选择不匹配的label，训练D（负向刺激
- 选择相匹配的label，训练G

实际的应用：生成有明确指向的信号

- 依据给定的特征label生成图片、文本、音频
- Image-to-Image Translation，pix2pix（物体色块-图片，卫星图-地图，深度信息-带透视的照片，人物抠图，人脸转正，照片补全，照片中去除讨厌的信息，边框-插画，素描-插画，卸妆-上妆，黑白-彩色，低分-超分，几种颜色-Palette，白天-黑夜，视频-换脸换衣服视频）
- 文本 to 文本（干的事情和Seq2Seq差不多？）
- 音频 to 音频（干的事情和Seq2Seq差不多？）
- 图片、文本、音频互相转换
- 其他（运动骨骼体-图片生成动态视频……）

![CGAN](<img/CGAN.png>)

### GAN (with Unpaired Data)

数据不成对，莫得标签，想要从一个Domain（向量空间）映射到另一个Domain（向量空间），就成无监督的任务了

![unpaired](<img/unpaired.jpg>)

G~x-y~：输入x domain的label（可以是离散的属性值，也可以是各种具有物理属性的向量）或者是来自G~y-x~的输出G(y)，输出与y domain同尺寸的G(x)

G~y-x~：输入y domain的label（可以是离散的属性值，也可以是各种具有物理属性的向量）或者是来自G~x-y~的输出G(x)，输出与x domain同尺寸的G(y)

D~y~：输入 [ G(x), y ] 的拼接数据，输出判断是否像y domain的(真伪二分类 或 0-1的回归)

D~x~：输入 [ G(y), x ] 的拼接数据，输出判断是否像x domain的(真伪二分类 或 0-1的回归)

训练：

![CycleGAN](<img/CycleGAN.png>)

实际的应用：风格迁移

- 图片 to 图片（照片-油画，别人脸上的妆容画到你脸上，三次元-二次元）
- 文本 to 文本（无监督翻译）
- 音频 to 音频
- 图片、文本、音频互相转换

注：x, y domain都是在预先训练时定死的，如果想要通用的风格混合可以看看这个[UniversalStyleTransfer](<https://github.com/Yijunmaverick/UniversalStyleTransfer>)

# Intro to NLP

![NLP_task](<img/NLP_task.jpg>)

- POS(Part-of-Speech) Tagging 输入词汇序列，输出词性序列
- Word Segmentation 分词：输入词汇序列，输出是否是单词结尾的二分类
- *Parsing 输入词汇序列，输出词性的树状结构
- *Coreference Resolution 指代消解，找出指代着同一个实体的词汇们
- Summarization 摘要
  - Extractive 选句子做摘抄：输入几个句子的文字，选择每个句子是否要被放入摘要中
  - Abstractive 创作摘要：Seq2Seq
- Machine Translation 翻译：Seq2Seq
- Grammar Error Correction：Seq2Seq
- Sentiment Classification 情绪分类，评论分类：二分类
- Stance Detection 立场侦测，评论是Support、Denying、Querying还是Commenting：输入两个序列，输出分类
- Veracity Prediction 实事侦测，新闻是真的还是假的：输入文章、评论、Wiki，输出二分类
- Natural Language Inference 自然语言推理：输入前提和假设（两个序列），输出分类（contradiction矛盾，entailment蕴含，neutral中立）
- Search Engine：……
- Question Answering
- NLU
  - Intent Classification 意图分类：是问问题还是提供信息？
  - Slot Filling
- Dialogue
  - Chatting (Chatbot)：记忆、Seq2Seq
  - Task-orient 任务：可以直接输入到输出硬train，也可以分为多个子问题子网络![task_oriented](<img/task_oriented.jpg>)
- Knowledge Graph：知识图谱的构建、运用知识图谱进行QA、Dialogue
- Name Entity Recognition(NER) 抽取实体：输入词汇序列，输出实例种类序列
- Relation Extraction 关系抽取：输入一段描述和两个实体，输出一个分类（两个实体之间的关系）

## BERT

![BERT](<img/BERT.jpg>)

## 什么是Pre-train model

以前Pre-train Model就相当于字典，且不管上下文，一个词（token）就对应一个向量（Word2vec、Glove）。至于英文词汇过多的问题，可以试试直接拿字母当输入。

但是对于句子“单身狗养了一只狗”中的狗的意思不一样，就不应该用相同的vec对待。

所以Pre-train Model就需要Contextualized Word Embedding，考虑上下文的信息。知道苹果（水果）和苹果（公司、品牌）的不同。

使用LSTM、Self-attention去深度搅就行了。

Treebased Modle在通用文本中并不能大幅增加准确率，只是在文法比较严谨的文本中表现较好，比如数学文章。

Pre-train的网络因为需要学习海量文本，所需强劲的表征能力，网络就越来越深，个人研究者就尝试精简网络。

## 如何将task specific model与Pre-train结合，如何Fine-tune

先把序列输入Pre-train Model，再把输出的向量输入你自己的task specific model中，搅和。

输入：

- 一个句子序列：直接扔进去
- 多个句子序列：将多个序列拼接

输出：

- 整个序列输出一个class（[CLS]指定符），在输入进task specific model
- 每个token输出一个class（[CLS]指定符），再输入进task specific model
- Copy from Input（[CLS]指定符），提问和文章拼接作为输入，将文章部分的输出作为输入，输入进task specific model
- General Sequence 输入一个序列，输出一个序列
  - Seq2Seq，Pre-train Model作为编码器，task specific model作为解码器（但是这样的话，部分的网络没有Pre-train的经验了）
  - 蹦豆式生成，类似朴素RNN的文本生成

搅和：

- 固定住Pre-train Model，只train task specific model
- train整体。但是Pre-train Model太大，电脑带不动，于是就插入一些Adapter进去，搅和的时候，Pre-train Model中就只调Adapter的就行了。
